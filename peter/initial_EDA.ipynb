{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Relation\n",
    "\n",
    "`ais_tracks` & `radar_tracks`: both contain 27416 corresponding tracks identified by both radar & ais. Can consider them as training\n",
    "\n",
    "`tracks_tagged`: 9013 tagged radar tracks by users in M2. \n",
    "\n",
    "`tagged_detections`: 6756272 timestamps and 9020 individual tracks in total, contains ALL tracks in `tracks_tagged`. The remaining 7 tracks are from AIS, 5 of which overlap with `ais_tracks`\n",
    "\n",
    "`radar_detections`: 7387790 timestamps and 19947 radar tracks; 15345 of which are associated with radar/ais_tracks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of ais_tracks: 27416\n",
      "Length of radar_tracks: 27416\n",
      "Length of radar_detections: 7387790\n",
      "Length of tagged_detections: 6756272\n",
      "Length of tracks_tagged: 9013\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Define file paths\n",
    "ais_tracks_path = '../data/tracks_ais.csv'\n",
    "radar_tracks_path = '../data/tracks_radar.csv'\n",
    "radar_detections_path = '../data/detections_radar.csv'\n",
    "tagged_detections_path = '../data/detections_tagged.csv'\n",
    "tracks_tagged_path = '../data/tracks_tagged.csv'\n",
    "\n",
    "ais_tracks = pd.read_csv(ais_tracks_path)\n",
    "radar_tracks = pd.read_csv(radar_tracks_path)\n",
    "radar_detections = pd.read_csv(radar_detections_path)\n",
    "tagged_detections = pd.read_csv(tagged_detections_path)\n",
    "tracks_tagged = pd.read_csv(tracks_tagged_path)\n",
    "\n",
    "print(\"Length of ais_tracks:\", len(ais_tracks))\n",
    "print(\"Length of radar_tracks:\", len(radar_tracks))\n",
    "print(\"Length of radar_detections:\", len(radar_detections))\n",
    "print(\"Length of tagged_detections:\", len(tagged_detections))\n",
    "print(\"Length of tracks_tagged:\", len(tracks_tagged))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique ais_tracks_id count: 27416\n",
      "Unique radar_tracks_id count: 27416\n",
      "Unique radar_detections_id count: 19947\n",
      "Unique tagged_detections_id count: 9020\n",
      "Unique tracks_tagged_id count: 9013\n"
     ]
    }
   ],
   "source": [
    "ais_tracks_id = set(ais_tracks['id_track'])\n",
    "radar_tracks_id = set(radar_tracks['id_track'])\n",
    "radar_detections_id = set(radar_detections['id_track'])\n",
    "tagged_detections_id = set(tagged_detections['id_track'])\n",
    "tracks_tagged_id = set(tracks_tagged['id_track'])\n",
    "\n",
    "print(\"Unique ais_tracks_id count:\", len(ais_tracks_id))\n",
    "print(\"Unique radar_tracks_id count:\", len(radar_tracks_id))\n",
    "print(\"Unique radar_detections_id count:\", len(radar_detections_id))\n",
    "print(\"Unique tagged_detections_id count:\", len(tagged_detections_id))\n",
    "print(\"Unique tracks_tagged_id count:\", len(tracks_tagged_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique assoc_id: 16591\n",
      "Number of unique id_track: 19947\n",
      "Number of unique assoc_id that are also in ais_tracks: 15345\n",
      "Missing in AIS: 1246 tracks\n",
      "Total number of unique (id_track, assoc_id) pairings: 19947\n"
     ]
    }
   ],
   "source": [
    "len1 = len(set(radar_detections['assoc_id']))\n",
    "len2 = len(set(radar_detections['id_track']))\n",
    "len3 = len(set(radar_detections['assoc_id']) & set(ais_tracks['id_track']))\n",
    "len4 = len(radar_detections[['id_track', 'assoc_id']].drop_duplicates())\n",
    "\n",
    "print(f'Number of unique assoc_id: {len1}')\n",
    "print(f'Number of unique id_track: {len2}')\n",
    "print(f'Number of unique assoc_id that are also in ais_tracks: {len3}')\n",
    "print(f'Missing in AIS: {len1 - len3} tracks')\n",
    "print(f'Total number of unique (id_track, assoc_id) pairings: {len4}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_track</th>\n",
       "      <th>assoc_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36979855</td>\n",
       "      <td>36979840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32063462</td>\n",
       "      <td>32065809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31251315</td>\n",
       "      <td>31251147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37731466</td>\n",
       "      <td>37731774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38363988</td>\n",
       "      <td>38366686</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_track  assoc_id\n",
       "0  36979855  36979840\n",
       "1  32063462  32065809\n",
       "2  31251315  31251147\n",
       "3  37731466  37731774\n",
       "4  38363988  38366686"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_assoc_id = set(radar_detections['assoc_id']) - (set(radar_detections['assoc_id']) & set(ais_tracks['id_track']))\n",
    "missing_rows = radar_detections[radar_detections['assoc_id'].isin(missing_assoc_id)]\n",
    "\n",
    "missing_rows[['id_track', 'assoc_id']].sample(5, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_track</th>\n",
       "      <th>id_site</th>\n",
       "      <th>id_m2</th>\n",
       "      <th>source</th>\n",
       "      <th>duration</th>\n",
       "      <th>alarm</th>\n",
       "      <th>min_speed</th>\n",
       "      <th>max_speed</th>\n",
       "      <th>avg_speed</th>\n",
       "      <th>curviness</th>\n",
       "      <th>...</th>\n",
       "      <th>dest</th>\n",
       "      <th>eta_month</th>\n",
       "      <th>eta_day</th>\n",
       "      <th>eta_hour</th>\n",
       "      <th>eta_minute</th>\n",
       "      <th>type_m2</th>\n",
       "      <th>sdate</th>\n",
       "      <th>stime</th>\n",
       "      <th>ldate</th>\n",
       "      <th>ltime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id_track, id_site, id_m2, source, duration, alarm, min_speed, max_speed, avg_speed, curviness, heading_mean, heading_std, turning_mean, turning_std, duration_z, distance, distance_o, assoc_str, assoc_id, tagged, has_photos, confidence, detections, mmsi, type, dim_a, dim_b, dim_c, dim_d, draft, dest, eta_month, eta_day, eta_hour, eta_minute, type_m2, sdate, stime, ldate, ltime]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 40 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming radar_detections and ais_tracks are already loaded as DataFrames\n",
    "filtered_radar_detections = radar_detections[~radar_detections['assoc_id'].isin(ais_tracks['id_track'])]\n",
    "filtered_radar_detections['assoc_id'].sample(3).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Radar Detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by assoc_id and collect all unique id_track values into sets\n",
    "assoc_track_df = radar_detections.groupby('assoc_id')['id_track'].apply(lambda x: set(x.dropna().unique())).reset_index()\n",
    "\n",
    "# Display the first few rows\n",
    "print(\"Number of unique associated IDs:\", len(assoc_track_df))\n",
    "print(\"\\nFirst few rows:\")\n",
    "display(assoc_track_df.head())\n",
    "\n",
    "# Display some statistics\n",
    "print(\"\\nStatistics about track sets:\")\n",
    "print(\"Average number of tracks per assoc_id:\", assoc_track_df['id_track'].apply(len).mean())\n",
    "print(\"Maximum number of tracks for an assoc_id:\", assoc_track_df['id_track'].apply(len).max())\n",
    "print(\"Number of assoc_ids with no tracks:\", assoc_track_df['id_track'].apply(len).eq(0).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Size EDAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ais_tracks['length'] = ais_tracks['dim_a'] + ais_tracks['dim_b']\n",
    "ais_tracks['width'] = ais_tracks['dim_c'] + ais_tracks['dim_d']\n",
    "\n",
    "ais_tracks_with_size = ais_tracks.dropna(subset=['width', 'length'])\n",
    "length_width_filter = (ais_tracks['length'] > 0) & (ais_tracks['width'] > 0)\n",
    "ais_tracks_with_size = ais_tracks_with_size[length_width_filter]\n",
    "\n",
    "print(f'Total number of AIS tracks with size info: {len(ais_tracks_with_size)}')\n",
    "\n",
    "ais_tracks_with_size['length'].describe()\n",
    "ais_tracks_with_size['width'].describe()\n",
    "ais_tracks_with_size['length'].hist(bins=100, edgecolor='black')\n",
    "plt.title('Histogram of AIS Track Lengths')\n",
    "plt.xlabel('Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top types by count\n",
    "type_counts = ais_tracks_with_size['type_m2'].value_counts()\n",
    "top_types = type_counts.head(len(type_counts))\n",
    "print(top_types)\n",
    "\n",
    "# Create a new column with aggregated types\n",
    "ais_tracks_with_size['type_m2_agg'] = ais_tracks_with_size['type_m2'].apply(\n",
    "    lambda x: x if x in top_types else 'other'\n",
    ")\n",
    "\n",
    "# Create a figure with two subplots side by side\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(7, 7))\n",
    "\n",
    "# Plot length distribution for each type\n",
    "for type_name in ais_tracks_with_size['type_m2_agg'].unique():\n",
    "    type_data = ais_tracks_with_size[ais_tracks_with_size['type_m2_agg'] == type_name]\n",
    "    ax1.hist(type_data['length'], bins=30, alpha=0.5, label=type_name)\n",
    "\n",
    "ax1.set_title('Length Distribution by Type')\n",
    "ax1.set_xlabel('Length (meters)')\n",
    "ax1.set_ylabel('Count')\n",
    "ax1.legend()\n",
    "ax1.grid(True)\n",
    "\n",
    "# Plot width distribution for each type\n",
    "for type_name in ais_tracks_with_size['type_m2_agg'].unique():\n",
    "    type_data = ais_tracks_with_size[ais_tracks_with_size['type_m2_agg'] == type_name]\n",
    "    ax2.hist(type_data['width'], bins=30, alpha=0.5, label=type_name)\n",
    "\n",
    "ax2.set_title('Width Distribution by Type')\n",
    "ax2.set_xlabel('Width (meters)')\n",
    "ax2.set_ylabel('Count')\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print summary statistics for each type\n",
    "print(\"\\nSummary Statistics:\")\n",
    "print(\"\\nLength Statistics by Type:\")\n",
    "print(ais_tracks_with_size.groupby('type_m2_agg')['length'].describe())\n",
    "print(\"\\nWidth Statistics by Type:\")\n",
    "print(ais_tracks_with_size.groupby('type_m2_agg')['width'].describe())\n",
    "\n",
    "# Print the original type counts for reference\n",
    "print(\"\\nOriginal Type Counts:\")\n",
    "print(type_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Noted that class-b vessels don't have corresponding size information in AIS_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_subset = ['min_speed', 'max_speed', 'avg_speed', 'curviness', 'heading_mean', 'heading_std', 'turning_mean', 'turning_std', 'duration_z', 'distance', 'distance_o']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create correlation matrix for features_subset\n",
    "correlation_matrix = radar_tracks[features_subset].corr()\n",
    "\n",
    "# Create a heatmap of the correlation matrix\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_matrix, \n",
    "            annot=True,  # Show correlation values\n",
    "            cmap='coolwarm',  # Use a diverging color palette\n",
    "            center=0,  # Center the colormap at 0\n",
    "            fmt='.2f',  # Round correlation values to 2 decimal places\n",
    "            square=True)  # Make the plot square\n",
    "\n",
    "plt.title('Correlation Matrix of Radar Track Features')\n",
    "plt.tight_layout()  # Adjust layout to prevent label cutoff\n",
    "plt.show()\n",
    "\n",
    "# Print the correlation matrix as a table for reference\n",
    "print(\"\\nCorrelation Matrix:\")\n",
    "display(correlation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Split features and target\n",
    "X = radar_tracks[features_subset]  # Features (e.g., avg_speed, curviness, turning_mean, turning_std)\n",
    "\n",
    "type_counts = radar_tracks['type_m2'].value_counts()\n",
    "top_types = type_counts.head(len(type_counts)).index\n",
    "\n",
    "# Create a new column with aggregated types\n",
    "radar_tracks['type_m2_agg'] = radar_tracks['type_m2'].apply(\n",
    "    lambda x: x if x in top_types else 'other'\n",
    ")\n",
    "\n",
    "y = radar_tracks['type_m2_agg']  # Target (Vessel type category)\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "ship2num = {}\n",
    "num2ship = {}\n",
    "\n",
    "num = 0\n",
    "for vessel in y.unique():\n",
    "    ship2num[vessel] = num\n",
    "    num2ship[num] = vessel\n",
    "    num += 1\n",
    "\n",
    "y_numeric = y.map(ship2num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split (80:20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_numeric, test_size=0.2, stratify=y_numeric, random_state=42)\n",
    "\n",
    "# Define XGBoost model\n",
    "model = xgb.XGBClassifier(\n",
    "    objective='multi:softmax',  # Use 'multi:softprob' if you want probability outputs\n",
    "    num_class=len(y.unique()),\n",
    "    eval_metric='mlogloss',\n",
    "    eta=0.1,  # Learning rate\n",
    "    max_depth=6,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Perform 4-fold cross-validation\n",
    "kf = StratifiedKFold(n_splits=4, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(model, X_train, y_train, cv=kf, scoring='accuracy')\n",
    "\n",
    "print(f\"4-Fold CV Accuracy: {cv_scores.mean():.4f} ± {cv_scores.std():.4f}\")\n",
    "\n",
    "# Train on full training set\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Test set predictions\n",
    "y_pred = model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Test Set Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Create confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Create a figure with a larger size\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Create heatmap of confusion matrix\n",
    "sns.heatmap(cm, \n",
    "            annot=True,  # Show numbers in cells\n",
    "            fmt='d',     # Format as integers\n",
    "            cmap='Blues',  # Use blue color scheme\n",
    "            xticklabels=list(ship2num.keys()),  # Use vessel type names for x-axis\n",
    "            yticklabels=list(ship2num.keys()))  # Use vessel type names for y-axis\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Confusion Matrix - Vessel Type Classification')\n",
    "plt.xlabel('Predicted Vessel Type')\n",
    "plt.ylabel('True Vessel Type')\n",
    "plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for better readability\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()  # Adjust layout to prevent label cutoff\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# Print classification report for detailed metrics\n",
    "# print(\"\\nClassification Report:\")\n",
    "# print(classification_report(y_test, y_pred, target_names=list(ship2num.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'cargo ship & tanker ship get mixed up: but it is probably ok!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at Hand-Written Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge radar_detections with ais_tracks using inner join\n",
    "merged_detections = radar_detections.merge(\n",
    "    ais_tracks[['id_track', 'type_m2']], \n",
    "    left_on='assoc_id',  \n",
    "    right_on='id_track',  \n",
    "    how='inner'  \n",
    ")\n",
    "\n",
    "print(\"Original radar_detections shape:\", radar_detections.shape)\n",
    "print(\"Merged dataset shape:\", merged_detections.shape)\n",
    "print(\"\\nNumber of matched entries:\", len(merged_detections))\n",
    "print(\"Number of unmatched radar detections:\", len(radar_detections) - len(merged_detections))\n",
    "\n",
    "# Display the first few rows of the merged dataset\n",
    "print(\"\\nFirst few rows of merged dataset:\")\n",
    "display(merged_detections.head())\n",
    "\n",
    "# Display type distribution in merged dataset\n",
    "print(\"\\nType distribution in merged dataset:\")\n",
    "print(merged_detections['type_m2'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
