{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liuzehan/miniconda3/lib/python3.11/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import warnings\n",
    "import sys, os\n",
    "\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "ais_type_labels = '../../data/ais_type_labels.csv'\n",
    "cleaned_detections_path = '../../data/cleaned_data/preprocessed_radar_detections.csv'\n",
    "ais_type_labels = pd.read_csv(ais_type_labels)\n",
    "radar_detections = pd.read_csv(cleaned_detections_path)\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "MIN_PIXEL_SPAN = 2.5e-5 # Adds a minimum pixel span\n",
    "\n",
    "class TrajectoryRasterize():\n",
    "    def __init__(self, image_width, image_height):\n",
    "        self.width = image_width\n",
    "        self.height = image_height\n",
    "        \n",
    "    def standardize_coordinates(self, lats, longs, min_lat_span = None,\n",
    "                                min_long_span = None):\n",
    "        \"\"\"\n",
    "        Standardize the latitude and longitude coordinates to range (0,1)\n",
    "        This implementation preserves aspect ratio of the trajectory\n",
    "\n",
    "        Args:\n",
    "            lats: A vector of latitude coordinates\n",
    "            longs: A vector of longitude coordinates\n",
    "        \"\"\"\n",
    "        img_aspect_ratio = self.width / self.height\n",
    "        \n",
    "        # First compute the span of the latitude and longitudes\n",
    "        lat_max, lat_min = np.max(lats), np.min(lats)\n",
    "        long_max, long_min = np.max(longs), np.min(longs)\n",
    "        lat_span, long_span = lat_max - lat_min, long_max - long_min\n",
    "        \n",
    "        # Add a minimum span to prevent the image from being zoomed in too far\n",
    "        if min_lat_span is None:\n",
    "            min_lat_span = self.height * MIN_PIXEL_SPAN\n",
    "        if min_long_span is None:\n",
    "            min_long_span = self.width * MIN_PIXEL_SPAN\n",
    "            \n",
    "        # Now compute the correct latitude and longitude spans,\n",
    "        # after accounting for the image aspect ratio and minimum span\n",
    "        corrected_lat_span = np.max([min_lat_span, lat_span, long_span/img_aspect_ratio])\n",
    "        corrected_long_span = np.max([min_long_span, long_span, lat_span*img_aspect_ratio])\n",
    "        \n",
    "        # Now correct the minimum value of lat long\n",
    "        lat_mid = (lat_max + lat_min) / 2\n",
    "        lat_start = lat_mid - 0.5 * corrected_lat_span\n",
    "        long_mid = (long_max + long_min) / 2\n",
    "        long_start = long_mid - 0.5 * corrected_long_span\n",
    "        \n",
    "        # Now standardize the corrdinates to be in range [0, 1]\n",
    "        lat_standardized = (lats - lat_start) / corrected_lat_span\n",
    "        long_standardized = (longs - long_start) / corrected_long_span\n",
    "        return lat_standardized, long_standardized\n",
    "    \n",
    "    def assign_pixel_position(self, lat_std, long_std):\n",
    "        \"\"\"\n",
    "        Assign the pixel position within the rasterized image for each detection point\n",
    "\n",
    "        Args:\n",
    "            lat_std: standardized latitude\n",
    "            long_std: standardized longitude\n",
    "        \n",
    "        Returns:\n",
    "            An numpy array of shape (N, 2) with the row and column indices\n",
    "        \"\"\"\n",
    "        # We require the row / column indices to be of int type\n",
    "        row_idxs = np.minimum(np.floor(lat_std * self.height), self.height - 1).astype(np.int64)\n",
    "        col_idxs = np.minimum(np.floor(long_std * self.width), self.width - 1).astype(np.int64)\n",
    "        return np.vstack((row_idxs, col_idxs)).T\n",
    "        \n",
    "    def aggregate_pixels(self, speed, turning, indices):\n",
    "        \"\"\"\n",
    "        Aggregate the pixel level information\n",
    "\n",
    "        Args:\n",
    "            speed: Trajectory Speed data\n",
    "            turning: The turning (change of course) vector, value between 0 and 180\n",
    "            indices: row, col indices returned by assign_pixel_position\n",
    "        \n",
    "        Returns:\n",
    "            A 3D tensor with 3 channels (count, average_speed, max_speed)\n",
    "        \"\"\"\n",
    "        # Uses PyTorch indexing convension (C, H, W)\n",
    "        result = np.zeros((3, self.height, self.width), dtype = np.float32)\n",
    "        # C = 0 for count\n",
    "        # C = 1 for average Speed\n",
    "        # C = 2 for average turning\n",
    "        \n",
    "        for i in range(len(indices)):\n",
    "            r, c = indices[i, 0], indices[i, 1]\n",
    "            prev_count = result[0, r, c]\n",
    "            # Increment count, aggregate average and update max\n",
    "            result[0, r, c] += 1\n",
    "            result[1, r, c] = (prev_count * result[1, r, c] + speed[i])/(prev_count + 1)\n",
    "            result[2, r, c] = (prev_count * result[2, r, c] + turning[i])/(prev_count + 1) \n",
    "        return result\n",
    "    \n",
    "    def to_image(self, agg, speed_ceil = 22.5, bias = True):\n",
    "        \"\"\"\n",
    "        Standardize the tensor values given by aggregate_pixels to be integer\n",
    "        values between 0 and 255.\n",
    "\n",
    "        Args:\n",
    "            agg: object returned by aggregate_pixels\n",
    "            speed_ceil: The ceiling value for speed. Defaults to 22.5\n",
    "            bias: Add a bias to add pixels with detection point. Defaults to True\n",
    "            \n",
    "        Returns:\n",
    "            A numpy array with (H, W, C) layout with an int dtype.\n",
    "        \"\"\"\n",
    "        \n",
    "        # First computes the dynamic range of the image (Bias takes RGB value of 30)\n",
    "        dynamic_range = 225 if bias else 255\n",
    "        \n",
    "        # Simply clip all count values higher than 255 to 255\n",
    "        agg[0, :, :] = np.minimum(agg[0, :, :], dynamic_range)\n",
    "        # Computes the step for speed values\n",
    "        agg[1, :, :] = agg[1, :, :] * dynamic_range / speed_ceil\n",
    "        # Clip the speed values to 255\n",
    "        agg[1, :, :] = np.minimum(agg[1, :, :], dynamic_range)\n",
    "        # Normalize the turning values to range (0,255)\n",
    "        agg[2, :, :] *= dynamic_range / 180\n",
    "        \n",
    "        # Add a bias term to all detection points in the image\n",
    "        if bias:\n",
    "            mask = agg[0, :, :] > 0\n",
    "            agg += mask * 30\n",
    "\n",
    "        return np.moveaxis(agg.astype(np.uint8), 0, -1)\n",
    "    \n",
    "class VesselTrajectoryRasterize(TrajectoryRasterize):\n",
    "    def __init__(self, image_width, image_height, trajectory_data: pd.DataFrame):\n",
    "        super().__init__(image_width, image_height)\n",
    "        self.data = trajectory_data\n",
    "    \n",
    "    def get_track(self, track_id):\n",
    "        detections = self.data[self.data[\"id_track\"] == track_id]\n",
    "        detections = detections.sort_values(by = \"datetime\", ascending=True)\n",
    "        n = len(detections)\n",
    "        if n == 0: raise RuntimeError(f\"Track id {track_id} has empty record\")\n",
    "        \n",
    "        # Compute the turning vector, the turning at the initial point is always\n",
    "        # set to 0\n",
    "        turning = np.nan_to_num(np.abs(detections[\"course\"] - detections[\"course\"].shift(1)), nan = 0.0)\n",
    "        turning = np.where(turning < 180, turning, turning - 180)\n",
    "        # Always bound the turning between 0 and 180.\n",
    "        \n",
    "        # We only need to keep track of these:\n",
    "        return {\n",
    "            \"lats\" : detections[\"latitude\"].to_numpy(),\n",
    "            \"longs\" : detections[\"longitude\"].to_numpy(),\n",
    "            \"speed\" : detections[\"speed\"].to_numpy(),\n",
    "            \"turning\" : turning\n",
    "        }\n",
    "        \n",
    "    def __call__(self, track_id, speed_ceil = 22.5, bias = True):\n",
    "        \"\"\"\n",
    "        Perform an entire sequence for vessel trajectory rasterization\n",
    "\n",
    "        Args:\n",
    "            track_id: \n",
    "            speed_ceil: Clamp value for speed channels. Defaults to 25.5.\n",
    "            bias: Add a bias to each pixel with detection point. Default to True.\n",
    "        \"\"\"\n",
    "        data = self.get_track(track_id)\n",
    "        lat, long = self.standardize_coordinates(data[\"lats\"], data[\"longs\"])\n",
    "        pixel_idx = self.assign_pixel_position(lat, long)\n",
    "        agg_np = self.aggregate_pixels(data[\"speed\"], data[\"turning\"], pixel_idx)\n",
    "        return self.to_image(agg_np, speed_ceil, bias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rasterizer = VesselTrajectoryRasterize(image_width=224, image_height=224, trajectory_data=radar_detections)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14204/14204 [01:23<00:00, 171.06it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "path_name = 'track_images/'\n",
    "track_ids = list(radar_detections[\"id_track\"].unique())\n",
    "\n",
    "for id in tqdm(track_ids):\n",
    "    img = Image.fromarray(rasterizer(id))\n",
    "    img.save(path_name + f\"{id}.jpg\", quality=95)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
