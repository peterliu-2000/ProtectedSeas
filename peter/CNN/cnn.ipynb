{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import warnings\n",
    "import sys, os\n",
    "import torch\n",
    "from torch.nn import nn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "ais_type_label_path = '../../data/labels/ais_type_labels_radar_detections.csv'\n",
    "image_path = 'track_images/'\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"Failed to load image Python extension\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Background\n",
    "\n",
    "Run track_rasterizer.py: converts cleaned_radar_detections into images stored in track_images, ready to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "NUM_HIDDEN_1 = 32\n",
    "NUM_HIDDEN_2 = 64\n",
    "NUM_HIDDEN_3 = 128\n",
    "\n",
    "from core.DICT import TYPE_to_LABEL\n",
    "NUM_CLASSES = len(TYPE_to_LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader_imgs import get_type_datasets\n",
    "\n",
    "train_loader, val_loader, test_loader = get_type_datasets(ais_type_label_path, image_path, batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liuzehan/miniconda3/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/Users/liuzehan/miniconda3/lib/python3.11/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c1017RegisterOperatorsD1Ev\n",
      "  Referenced from: <2BD1B165-EC09-3F68-BCE4-8FE4E70CA7E2> /Users/liuzehan/miniconda3/lib/python3.11/site-packages/torchvision/image.so\n",
      "  Expected in:     <25C510F7-7AEE-3D64-80ED-95874DC6BECD> /Users/liuzehan/miniconda3/lib/python3.11/site-packages/torch/lib/libtorch_cpu.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 224, 224])\n",
      "torch.Size([32])\n",
      "tensor([2, 0, 1, 1, 1, 0, 1, 2, 2, 0, 1, 2, 1, 1, 6, 6, 1, 2, 0, 2, 1, 1, 3, 1,\n",
      "        6, 6, 2, 1, 2, 6, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "for next_batch in train_loader:\n",
    "    print(next_batch[0].shape)\n",
    "    print(next_batch[1].shape)\n",
    "    print(next_batch[1])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNNBaseline(nn.Module):\n",
    "    def __init__(self,  num_hidden_1, num_hidden_2, num_hidden_3, num_classes):\n",
    "        super(CNNBaseline, self).__init__()\n",
    "        self.num_hidden_1 = num_hidden_1\n",
    "        self.num_hidden_2 = num_hidden_2\n",
    "        self.num_hidden_3 = num_hidden_3\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        self.features = nn.Sequential(\n",
    "            # Conv Block 1\n",
    "            # Input: 3*224*224\n",
    "            nn.Conv2d(in_channels=3, out_channels=self.num_hidden_1, kernel_size=3, padding=1),  # -> (h1, 224, 224)\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2),  # -> (h1, 112, 112)\n",
    "            nn.Dropout(p=0.25),\n",
    "\n",
    "            # Conv Block 2\n",
    "            nn.Conv2d(self.num_hidden_1, self.num_hidden_2, kernel_size=3, padding=1),  # -> (h2, 112, 112)\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2),  # -> (h2, 56, 56)\n",
    "            nn.Dropout(p=0.25),\n",
    "\n",
    "            # Conv Block 3\n",
    "            nn.Conv2d(self.num_hidden_2, self.num_hidden_3, kernel_size=3, padding=1),  # -> (h3, 56, 56)\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2),  # -> (h3, 28, 28)\n",
    "            nn.Dropout(p=0.25)\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),  # -> (h3 * 28 * 28)\n",
    "            nn.Linear(self.num_hidden_3 * 28 * 28, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(512, self.num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import copy\n",
    "\n",
    "def train(model: nn.Module, \n",
    "                train_loader: DataLoader, \n",
    "                val_loader: DataLoader, \n",
    "                optimizer: optim.Optimizer, \n",
    "                device: torch.device,\n",
    "                num_epochs: int,\n",
    "                scheduler: None, ) -> tuple[list[float], list[float], list[float], list[float]]:\n",
    "    \n",
    "    TRAIN_LOSSES = []\n",
    "    TRAIN_ACC = []\n",
    "    VAL_LOSSES = []\n",
    "    VAL_ACC = []\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for inputs, targets in tqdm(train_loader, desc=\"Training\", leave=False):\n",
    "            inputs, targets = inputs.to(device), targets.to(device) \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()    \n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "            total += targets.size(0)\n",
    "            \n",
    "        train_loss = running_loss / total\n",
    "        train_acc = correct / total\n",
    "        TRAIN_LOSSES.append(train_loss)\n",
    "        TRAIN_ACC.append(train_acc)\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "        model.eval()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():   \n",
    "            for inputs, targets in tqdm(val_loader, desc=\"Evaluating\", leave=False):\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                _, predicted = outputs.max(1)\n",
    "                correct += (predicted == targets).sum().item()\n",
    "                total += targets.size(0)\n",
    "\n",
    "        val_loss = running_loss / total\n",
    "        val_acc = correct / total\n",
    "        VAL_LOSSES.append(val_loss)\n",
    "        VAL_ACC.append(val_acc) \n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
    "        print(f\"Val   Loss: {val_loss:.4f} | Val   Acc: {val_acc:.4f}\")\n",
    "\n",
    "    return TRAIN_LOSSES, TRAIN_ACC, VAL_LOSSES, VAL_ACC, best_model_wts, best_val_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Train Loss: 1.1232 | Train Acc: 0.6322\n",
      "Val   Loss: 0.9439 | Val   Acc: 0.6852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10\n",
      "Train Loss: 0.9298 | Train Acc: 0.6904\n",
      "Val   Loss: 0.9134 | Val   Acc: 0.6915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10\n",
      "Train Loss: 0.8850 | Train Acc: 0.7047\n",
      "Val   Loss: 0.9035 | Val   Acc: 0.6859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10\n",
      "Train Loss: 0.8403 | Train Acc: 0.7112\n",
      "Val   Loss: 0.8575 | Val   Acc: 0.7092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "Train Loss: 0.8015 | Train Acc: 0.7278\n",
      "Val   Loss: 0.8583 | Val   Acc: 0.7106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10\n",
      "Train Loss: 0.7646 | Train Acc: 0.7402\n",
      "Val   Loss: 0.8512 | Val   Acc: 0.7120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n",
      "Train Loss: 0.7224 | Train Acc: 0.7511\n",
      "Val   Loss: 0.8579 | Val   Acc: 0.7063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10\n",
      "Train Loss: 0.6770 | Train Acc: 0.7699\n",
      "Val   Loss: 0.8543 | Val   Acc: 0.7211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n",
      "Train Loss: 0.6361 | Train Acc: 0.7848\n",
      "Val   Loss: 0.8805 | Val   Acc: 0.7077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10\n",
      "Train Loss: 0.5966 | Train Acc: 0.7983\n",
      "Val   Loss: 0.8858 | Val   Acc: 0.7085\n"
     ]
    }
   ],
   "source": [
    "cnn_baseline_1 = CNNBaseline(NUM_HIDDEN_1, NUM_HIDDEN_2, NUM_HIDDEN_3, NUM_CLASSES).to(device)\n",
    "\n",
    "train_config = {\n",
    "    \"model\": cnn_baseline_1,\n",
    "    \"train_loader\" : train_loader,\n",
    "    \"val_loader\" : val_loader,\n",
    "    \"optimizer\" : optim.Adam(cnn_baseline_1.parameters(), lr=1e-3),\n",
    "    \"device\" : device,\n",
    "    \"num_epochs\" : 10,\n",
    "    \"scheduler\": None\n",
    "}\n",
    "\n",
    "train_loss, train_acc, val_loss, val_acc, best_model_wts, best_val_loss = train(**train_config)\n",
    "torch.save(best_model_wts, \"models/cnn_baseline_best_10.pth\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Train Loss: 0.6839 | Train Acc: 0.7646\n",
      "Val   Loss: 0.8251 | Val   Acc: 0.7120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10\n",
      "Train Loss: 0.6641 | Train Acc: 0.7706\n",
      "Val   Loss: 0.8265 | Val   Acc: 0.7169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10\n",
      "Train Loss: 0.6527 | Train Acc: 0.7759\n",
      "Val   Loss: 0.8300 | Val   Acc: 0.7155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10\n",
      "Train Loss: 0.6433 | Train Acc: 0.7833\n",
      "Val   Loss: 0.8349 | Val   Acc: 0.7148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "Train Loss: 0.6305 | Train Acc: 0.7817\n",
      "Val   Loss: 0.8395 | Val   Acc: 0.7162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10\n",
      "Train Loss: 0.6143 | Train Acc: 0.7879\n",
      "Val   Loss: 0.8421 | Val   Acc: 0.7197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n",
      "Train Loss: 0.6079 | Train Acc: 0.7916\n",
      "Val   Loss: 0.8451 | Val   Acc: 0.7183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10\n",
      "Train Loss: 0.5869 | Train Acc: 0.8011\n",
      "Val   Loss: 0.8503 | Val   Acc: 0.7225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n",
      "Train Loss: 0.5805 | Train Acc: 0.8043\n",
      "Val   Loss: 0.8563 | Val   Acc: 0.7190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10\n",
      "Train Loss: 0.5671 | Train Acc: 0.8076\n",
      "Val   Loss: 0.8562 | Val   Acc: 0.7197\n"
     ]
    }
   ],
   "source": [
    "# 1. Rebuild the model architecture\n",
    "cnn_baseline_1 = CNNBaseline(NUM_HIDDEN_1, NUM_HIDDEN_2, NUM_HIDDEN_3, NUM_CLASSES).to(device)\n",
    "\n",
    "# 2. Load the previously saved weights\n",
    "checkpoint_path = \"models/cnn_baseline_best_10.pth\"\n",
    "cnn_baseline_1.load_state_dict(torch.load(checkpoint_path))\n",
    "\n",
    "# 3. Set up the optimizer again\n",
    "optimizer = optim.Adam(cnn_baseline_1.parameters(), lr=1e-4)\n",
    "\n",
    "# 4. Define the new training config (next 10 epochs)\n",
    "train_config_resume = {\n",
    "    \"model\": cnn_baseline_1,\n",
    "    \"train_loader\": train_loader,\n",
    "    \"val_loader\": val_loader,\n",
    "    \"optimizer\": optimizer,\n",
    "    \"device\": device,\n",
    "    \"num_epochs\": 10,\n",
    "    \"scheduler\": None\n",
    "}\n",
    "\n",
    "# 5. Resume training\n",
    "train_loss_2, train_acc_2, val_loss_2, val_acc_2, best_model_wts_2, best_val_loss_2 = train(**train_config_resume)\n",
    "\n",
    "# 6. Save the updated best model\n",
    "torch.save(best_model_wts_2, \"models/cnn_baseline_best_20.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNNSimple(nn.Module):\n",
    "    def __init__(self,  num_hidden_1, num_hidden_2, num_classes):\n",
    "        super(CNNSimple, self).__init__()\n",
    "        self.num_hidden_1 = num_hidden_1\n",
    "        self.num_hidden_2 = num_hidden_2\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        self.features = nn.Sequential(\n",
    "            # Conv Block 1\n",
    "            # Input: 3*224*224\n",
    "            nn.Conv2d(in_channels=3, out_channels=self.num_hidden_1, kernel_size=3, padding=1),  # -> (h1, 224, 224)\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2),  # -> (h1, 112, 112)\n",
    "            nn.Dropout(p=0.25),\n",
    "\n",
    "            # Conv Block 2\n",
    "            nn.Conv2d(self.num_hidden_1, self.num_hidden_2, kernel_size=3, padding=1),  # -> (h2, 112, 112)\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2),  # -> (h2, 56, 56)\n",
    "            nn.Dropout(p=0.25),\n",
    "\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),  # -> (h3 * 56 * 56)\n",
    "            nn.Linear(self.num_hidden_2 * 56 * 56, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(256, self.num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Train Loss: 1.1389 | Train Acc: 0.6430\n",
      "Val   Loss: 1.0041 | Val   Acc: 0.6585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10\n",
      "Train Loss: 0.9428 | Train Acc: 0.6862\n",
      "Val   Loss: 0.9938 | Val   Acc: 0.6585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10\n",
      "Train Loss: 0.9008 | Train Acc: 0.7011\n",
      "Val   Loss: 0.9862 | Val   Acc: 0.6556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10\n",
      "Train Loss: 0.8569 | Train Acc: 0.7072\n",
      "Val   Loss: 0.9316 | Val   Acc: 0.6810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "Train Loss: 0.8173 | Train Acc: 0.7240\n",
      "Val   Loss: 0.9165 | Val   Acc: 0.6796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10\n",
      "Train Loss: 0.7721 | Train Acc: 0.7403\n",
      "Val   Loss: 0.9195 | Val   Acc: 0.6880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n",
      "Train Loss: 0.7271 | Train Acc: 0.7523\n",
      "Val   Loss: 0.9145 | Val   Acc: 0.6993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10\n",
      "Train Loss: 0.6780 | Train Acc: 0.7672\n",
      "Val   Loss: 0.9346 | Val   Acc: 0.7007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n",
      "Train Loss: 0.6216 | Train Acc: 0.7830\n",
      "Val   Loss: 0.9535 | Val   Acc: 0.6915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10\n",
      "Train Loss: 0.5749 | Train Acc: 0.8082\n",
      "Val   Loss: 0.9875 | Val   Acc: 0.6958\n"
     ]
    }
   ],
   "source": [
    "NUM_HIDDEN_1 = 16\n",
    "NUM_HIDDEN_2 = 32\n",
    "\n",
    "cnn_simple = CNNSimple(NUM_HIDDEN_1, NUM_HIDDEN_2, NUM_CLASSES).to(device)\n",
    "\n",
    "train_config = {\n",
    "    \"model\": cnn_simple,\n",
    "    \"train_loader\" : train_loader,\n",
    "    \"val_loader\" : val_loader,\n",
    "    \"optimizer\" : optim.Adam(cnn_simple.parameters(), lr=1e-3),\n",
    "    \"device\" : device,\n",
    "    \"num_epochs\" : 10,\n",
    "    \"scheduler\": None\n",
    "}\n",
    "\n",
    "train_loss, train_acc, val_loss, val_acc, best_model_wts, best_val_loss = train(**train_config)\n",
    "torch.save(best_model_wts, \"models/cnn_simple_best_10.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Train Loss: 0.7297 | Train Acc: 0.7483\n",
      "Val   Loss: 0.9145 | Val   Acc: 0.6993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10\n",
      "Train Loss: 0.7328 | Train Acc: 0.7471\n",
      "Val   Loss: 0.9145 | Val   Acc: 0.6993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10\n",
      "Train Loss: 0.7310 | Train Acc: 0.7482\n",
      "Val   Loss: 0.9145 | Val   Acc: 0.6993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10\n",
      "Train Loss: 0.7335 | Train Acc: 0.7506\n",
      "Val   Loss: 0.9145 | Val   Acc: 0.6993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "Train Loss: 0.7370 | Train Acc: 0.7487\n",
      "Val   Loss: 0.9145 | Val   Acc: 0.6993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10\n",
      "Train Loss: 0.7396 | Train Acc: 0.7477\n",
      "Val   Loss: 0.9145 | Val   Acc: 0.6993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n",
      "Train Loss: 0.7268 | Train Acc: 0.7444\n",
      "Val   Loss: 0.9145 | Val   Acc: 0.6993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10\n",
      "Train Loss: 0.7324 | Train Acc: 0.7449\n",
      "Val   Loss: 0.9145 | Val   Acc: 0.6993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n",
      "Train Loss: 0.7283 | Train Acc: 0.7482\n",
      "Val   Loss: 0.9145 | Val   Acc: 0.6993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10\n",
      "Train Loss: 0.7365 | Train Acc: 0.7426\n",
      "Val   Loss: 0.9145 | Val   Acc: 0.6993\n"
     ]
    }
   ],
   "source": [
    "# 1. Rebuild the model architecture\n",
    "cnn_simple = CNNSimple(NUM_HIDDEN_1, NUM_HIDDEN_2, NUM_CLASSES).to(device)\n",
    "\n",
    "# 2. Load the previously saved weights\n",
    "checkpoint_path = \"models/cnn_simple_best_10.pth\"\n",
    "cnn_simple.load_state_dict(torch.load(checkpoint_path))\n",
    "\n",
    "# 3. Set up the optimizer again\n",
    "optimizer = optim.Adam(cnn_baseline_1.parameters(), lr=1e-4)\n",
    "\n",
    "# 4. Define the new training config (next 10 epochs)\n",
    "train_config_resume = {\n",
    "    \"model\": cnn_simple,\n",
    "    \"train_loader\": train_loader,\n",
    "    \"val_loader\": val_loader,\n",
    "    \"optimizer\": optimizer,\n",
    "    \"device\": device,\n",
    "    \"num_epochs\": 10,\n",
    "    \"scheduler\": None\n",
    "}\n",
    "\n",
    "# 5. Resume training\n",
    "train_loss_2, train_acc_2, val_loss_2, val_acc_2, best_model_wts_2, best_val_loss_2 = train(**train_config_resume)\n",
    "\n",
    "# 6. Save the updated best model\n",
    "torch.save(best_model_wts_2, \"models/cnn_simple_best_20.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
