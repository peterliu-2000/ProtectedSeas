{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d701f8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from dataloader import *\n",
    "from CNN_Models import *\n",
    "from CNN_Training import *\n",
    "from model_io import *\n",
    "from utils.constants import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9e6868",
   "metadata": {},
   "source": [
    "Configure Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ec7b36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_path = \"\"\n",
    "image_path = current_path + \"data/images_activity\"\n",
    "label_path = current_path + \"data/activity_label.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a1c991",
   "metadata": {},
   "source": [
    "Setting Up Correct Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e5942a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently Using Device: mps\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if not torch.backends.mps.is_available():\n",
    "    if not torch.backends.mps.is_built():\n",
    "        print(\"MPS not available because the current PyTorch install was not \"\n",
    "            \"built with MPS enabled.\")\n",
    "    else:\n",
    "        print(\"MPS not available because the current MacOS version is not 12.3+ \"\n",
    "            \"and/or you do not have an MPS-enabled device on this machine.\")\n",
    "else:\n",
    "    device = torch.device(\"mps\")\n",
    "    \n",
    "print(f\"Currently Using Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888f7011",
   "metadata": {},
   "source": [
    "Obtain data loader, optimizer and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f2b1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train, valid) = get_activity_datasets(label_path, image_path, 16) # Use batch size of 16\n",
    "model = get_resnet18_classifier(ACT_N_CLASSES, dropout=0.2) # Use smaller dropout\n",
    "\n",
    "optimizer = get_optimizer(model, \"sgd\", lr = 1e-3, weight_decay = 1e-4, momentum = 0.9)\n",
    "scheduler = get_scheduler(optimizer, \"exponential\", gamma = 0.95)\n",
    "\n",
    "class_weights = torch.tensor([1,1,4,8,8,16,16,4], dtype = torch.float32).to(device) # Roughly invert class count\n",
    "loss_criterion = get_loss(class_weights / torch.sum(class_weights)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706aea7b",
   "metadata": {},
   "source": [
    "Train the Model in Stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f31435c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "one of the variables needed for gradient computation has been modified by an inplace operation: [MPSFloatType [16, 512, 7, 7]], which is output 0 of ReluBackward0, is at version 3; expected version 2 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 11\u001b[0m\n\u001b[1;32m      7\u001b[0m logger \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m : [], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalid_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m : [], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_acc\u001b[39m\u001b[38;5;124m\"\u001b[39m : [], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalid_acc\u001b[39m\u001b[38;5;124m\"\u001b[39m : []}\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m stage \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_stages):\n\u001b[0;32m---> 11\u001b[0m     \u001b[43mCNN_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch_per_stage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m              \u001b[49m\u001b[43mloss_criterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     model_save_name \u001b[38;5;241m=\u001b[39m model_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_stage\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstage\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     14\u001b[0m     save_checkpoint(model_save_name, model, optimizer, scheduler, logger)\n",
      "File \u001b[0;32m/Volumes/Documents/Documents/Research/ProtectedSeas/han/CNN_Training.py:150\u001b[0m, in \u001b[0;36mCNN_train\u001b[0;34m(model, train_data, valid_data, num_epochs, loss_fn, optimizer, scheduler, log, verbose)\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m running_loss \u001b[38;5;241m/\u001b[39m num_obs, num_correct \u001b[38;5;241m/\u001b[39m num_obs\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m--> 150\u001b[0m     train_loss, train_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m     valid_loss, valid_acc \u001b[38;5;241m=\u001b[39m validate()\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;66;03m# Update the learning rate and timestamp\u001b[39;00m\n",
      "File \u001b[0;32m/Volumes/Documents/Documents/Research/ProtectedSeas/han/CNN_Training.py:109\u001b[0m, in \u001b[0;36mCNN_train.<locals>.train_one_epoch\u001b[0;34m()\u001b[0m\n\u001b[1;32m    107\u001b[0m out \u001b[38;5;241m=\u001b[39m model(images)\n\u001b[1;32m    108\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(out, targets)\n\u001b[0;32m--> 109\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    112\u001b[0m \u001b[38;5;66;03m# Log the running loss\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: one of the variables needed for gradient computation has been modified by an inplace operation: [MPSFloatType [16, 512, 7, 7]], which is output 0 of ReluBackward0, is at version 3; expected version 2 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True)."
     ]
    }
   ],
   "source": [
    "# Save model checkpoint every 5 epochs\n",
    "num_stages = 3\n",
    "epoch_per_stage = 10\n",
    "model_path = current_path + \"model/\"\n",
    "\n",
    "# Initialize the logger object\n",
    "logger = {\"train_loss\" : [], \"valid_loss\" : [], \"train_acc\" : [], \"valid_acc\" : []}\n",
    "\n",
    "\n",
    "for stage in range(num_stages):\n",
    "    CNN_train(model, train, valid, epoch_per_stage,\n",
    "              loss_criterion, optimizer, scheduler, logger, True)\n",
    "    model_save_name = model_path + f\"model_stage{stage+1}.pth\"\n",
    "    save_checkpoint(model_save_name, model, optimizer, scheduler, logger)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b4d453",
   "metadata": {},
   "source": [
    "Evaluating A Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5a7642",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
