{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6550c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4f77ec2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will create trajectory images from smoothed detection points\n",
    "tracks = pd.read_csv(\"../data/activity_label.csv\")\n",
    "detections = pd.read_csv(\"../data/detections_tagged_smoothed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "f306522b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_PIXEL_SPAN = 5e-5 # Adds a minimum pixel span\n",
    "\n",
    "class TrajectoryRasterize():\n",
    "    def __init__(self, image_width, image_height):\n",
    "        self.width = image_width\n",
    "        self.height = image_height\n",
    "        \n",
    "    def standardize_coordinates(self, lats, longs, min_lat_span = None,\n",
    "                                min_long_span = None):\n",
    "        \"\"\"\n",
    "        Standardize the latitude and longitude coordinates to range (0,1)\n",
    "        This implementation preserves aspect ratio of the trajectory\n",
    "\n",
    "        Args:\n",
    "            lats: A vector of latitude coordinates\n",
    "            longs: A vector of longitude coordinates\n",
    "        \"\"\"\n",
    "        img_aspect_ratio = self.width / self.height\n",
    "        \n",
    "        # First compute the span of the latitude and longitudes\n",
    "        lat_max, lat_min = np.max(lats), np.min(lats)\n",
    "        long_max, long_min = np.max(longs), np.min(longs)\n",
    "        lat_span, long_span = lat_max - lat_min, long_max - long_min\n",
    "        \n",
    "        # Add a minimum span to prevent the image from being zoomed in too far\n",
    "        if min_lat_span is None:\n",
    "            min_lat_span = self.height * MIN_PIXEL_SPAN\n",
    "        if min_long_span is None:\n",
    "            min_long_span = self.width * MIN_PIXEL_SPAN\n",
    "            \n",
    "        # Now compute the correct latitude and longitude spans,\n",
    "        # after accounting for the image aspect ratio and minimum span\n",
    "        corrected_lat_span = np.max([min_lat_span, lat_span, long_span/img_aspect_ratio])\n",
    "        corrected_long_span = np.max([min_long_span, long_span, lat_span*img_aspect_ratio])\n",
    "        \n",
    "        # Now correct the minimum value of lat long\n",
    "        lat_mid = (lat_max + lat_min) / 2\n",
    "        lat_start = lat_mid - 0.5 * corrected_lat_span\n",
    "        long_mid = (long_max + long_min) / 2\n",
    "        long_start = long_mid - 0.5 * corrected_long_span\n",
    "        \n",
    "        # Now standardize the corrdinates to be in range [0, 1]\n",
    "        lat_standardized = (lats - lat_start) / corrected_lat_span\n",
    "        long_standardized = (longs - long_start) / corrected_long_span\n",
    "        return lat_standardized, long_standardized\n",
    "    \n",
    "    def assign_pixel_position(self, lat_std, long_std):\n",
    "        \"\"\"\n",
    "        Assign the pixel position within the rasterized image for each detection point\n",
    "\n",
    "        Args:\n",
    "            lat_std: standardized latitude\n",
    "            long_std: standardized longitude\n",
    "        \n",
    "        Returns:\n",
    "            An numpy array of shape (N, 2) with the row and column indices\n",
    "        \"\"\"\n",
    "        # We require the row / column indices to be of int type\n",
    "        row_idxs = np.minimum(np.floor(lat_std * self.height), self.height - 1).astype(np.int64)\n",
    "        col_idxs = np.minimum(np.floor(long_std * self.width), self.width - 1).astype(np.int64)\n",
    "        return np.vstack((row_idxs, col_idxs)).T\n",
    "        \n",
    "    def aggregate_pixels(self, speed, turning, indices):\n",
    "        \"\"\"\n",
    "        Aggregate the pixel level information\n",
    "\n",
    "        Args:\n",
    "            speed: Trajectory Speed data\n",
    "            turning: The turning (change of course) vector, value between 0 and 180\n",
    "            indices: row, col indices returned by assign_pixel_position\n",
    "        \n",
    "        Returns:\n",
    "            A 3D tensor with 3 channels (count, average_speed, max_speed)\n",
    "        \"\"\"\n",
    "        # Uses PyTorch indexing convension (C, H, W)\n",
    "        result = np.zeros((3, self.height, self.width), dtype = np.float32)\n",
    "        # C = 0 for count\n",
    "        # C = 1 for average Speed\n",
    "        # C = 2 for average turning\n",
    "        \n",
    "        for i in range(len(indices)):\n",
    "            r, c = indices[i, 0], indices[i, 1]\n",
    "            prev_count = result[0, r, c]\n",
    "            # Increment count, aggregate average and update max\n",
    "            result[0, r, c] += 1\n",
    "            result[1, r, c] = (prev_count * result[1, r, c] + speed[i])/(prev_count + 1)\n",
    "            result[2, r, c] = (prev_count * result[2, r, c] + turning[i])/(prev_count + 1) \n",
    "        return result\n",
    "    \n",
    "    def to_image(self, agg, speed_ceil = 25.6):\n",
    "        \"\"\"\n",
    "        Standardize the tensor values given by aggregate_pixels to be integer\n",
    "        values between 0 and 255.\n",
    "\n",
    "        Args:\n",
    "            agg: object returned by aggregate_pixels\n",
    "            speed_ceil: The ceiling value for speed. Defaults to 25.5 (eg. all values greater than 25.5 will be clipped to 25.5).\n",
    "            \n",
    "        Returns:\n",
    "            A numpy array with (H, W, C) layout with an int dtype.\n",
    "        \"\"\"\n",
    "        # Simply clip all count values higher than 255 to 255\n",
    "        agg[0, :, :] = np.minimum(agg[0, :, :], 255)\n",
    "        # Computes the step for speed values\n",
    "        step = speed_ceil / 255\n",
    "        agg[1, :, :] = agg[1, :, :] / step\n",
    "        # Clip the speed values to 255\n",
    "        agg[1, :, :] = np.minimum(agg[1, :, :], 255)\n",
    "        # Normalize the turning values to range (0,255)\n",
    "        agg[2, :, :] *= 255 / 180\n",
    "\n",
    "        return np.moveaxis(agg.astype(np.uint8), 0, -1)\n",
    "    \n",
    "    def to_pytorch(self, agg, speed_ceil = 25.5):\n",
    "        \"\"\"\n",
    "        Standardze the tensor value given by aggregate_pixels to be float32\n",
    "        values between 0 and 1. Has the same effect as to_image.\n",
    "\n",
    "        Args:\n",
    "            agg: object returned by aggregate_pixels\n",
    "            speed_ceil: Ceiling values for speed. Defaults to 25.5.\n",
    "        \n",
    "        Returns:\n",
    "            A PyTorch Tensor.\n",
    "        \"\"\"\n",
    "        # Simply clip all count values higher than 255 to 255\n",
    "        agg[0, :, :] = np.minimum(agg[0, :, :], 255)\n",
    "        # Computes the step for speed values\n",
    "        step = speed_ceil / 255\n",
    "        agg[1, :, :] = agg[1, :, :] / step\n",
    "        # Clip the speed values to 255\n",
    "        agg[1, :, :] = np.minimum(agg[1, :, :], 255)\n",
    "        # Normalize the turning values to range (0,255)\n",
    "        agg[2, :, :] *= 255 / 180\n",
    "        # Normalize values in [0, 1]\n",
    "        agg /= 255\n",
    "        \n",
    "        return torch.from_numpy(agg)\n",
    "    \n",
    "    \n",
    "class VesselTrajectoryRasterize(TrajectoryRasterize):\n",
    "    def __init__(self, image_width, image_height, trajectory_data: pd.DataFrame):\n",
    "        super().__init__(image_width, image_height)\n",
    "        self.data = trajectory_data\n",
    "    \n",
    "    def get_track(self, track_id):\n",
    "        detections = self.data[self.data[\"id_track\"] == track_id]\n",
    "        detections = detections.sort_values(by = \"time\", ascending=True)\n",
    "        n = len(detections)\n",
    "        if n == 0: raise RuntimeError(f\"Track id {track_id} has empty record\")\n",
    "        \n",
    "        # Compute the turning vector, the turning at the initial point is always\n",
    "        # set to 0\n",
    "        turning = np.nan_to_num(np.abs(detections[\"course\"] - detections[\"course\"].shift(1)), nan = 0.0)\n",
    "        turning = np.where(turning < 180, turning, turning - 180)\n",
    "        # Always bound the turning between 0 and 180.\n",
    "        \n",
    "        # We only need to keep track of these:\n",
    "        return {\n",
    "            \"lats\" : detections[\"latitude\"].to_numpy(),\n",
    "            \"longs\" : detections[\"longitude\"].to_numpy(),\n",
    "            \"speed\" : detections[\"speed\"].to_numpy(),\n",
    "            \"turning\" : turning\n",
    "        }\n",
    "        \n",
    "    def __call__(self, track_id, output = \"torch\", speed_ceil = 25.5):\n",
    "        \"\"\"\n",
    "        Perform an entire sequence for vessel trajectory rasterization\n",
    "\n",
    "        Args:\n",
    "            track_id: \n",
    "            output: output mode, supports \"torch\" and \"image\". Defaults to \"torch\".\n",
    "            preserve_aspect_ratio: Defaults to True.\n",
    "            speed_ceil: Clamp value for speed channels. Defaults to 25.5.\n",
    "        \"\"\"\n",
    "        if output not in {\"torch\", \"image\"}:\n",
    "            raise RuntimeError(f\"Unknown output mode {output}\")\n",
    "        data = self.get_track(track_id)\n",
    "        lat, long = self.standardize_coordinates(data[\"lats\"], data[\"longs\"])\n",
    "        pixel_idx = self.assign_pixel_position(lat, long)\n",
    "        agg_np = self.aggregate_pixels(data[\"speed\"], data[\"turning\"], pixel_idx)\n",
    "        if output == \"image\":\n",
    "            return self.to_image(agg_np, speed_ceil)\n",
    "        else:\n",
    "            return self.to_pytorch(agg_np, speed_ceil)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c377265",
   "metadata": {},
   "source": [
    "Testing Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "d07b3ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stopped\n",
      "255 50 79\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "rasterizer = VesselTrajectoryRasterize(224, 224, detections)\n",
    "idx = np.random.choice(len(tracks))\n",
    "id = tracks.iloc[idx][\"id_track\"]\n",
    "print(tracks.iloc[idx][\"activity\"])\n",
    "result = rasterizer(id, \"image\")\n",
    "print(np.max(result[:,:,0]),np.max( result[:,:,1]), np.max(result[:,:,2]))\n",
    "\n",
    "img = Image.fromarray(result)\n",
    "img.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d314c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
